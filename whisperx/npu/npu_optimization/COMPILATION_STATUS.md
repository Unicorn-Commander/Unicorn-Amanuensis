# MLIR-AIE2 Compilation Status - Quick Reference

**Last Updated**: October 25, 2025
**Status**: PARTIAL SUCCESS - Blockers Identified

---

## TL;DR

‚úÖ **What Works**:
- NPU hardware detected and accessible
- Correct device configuration identified (`npu1`)
- MLIR syntax errors fixed
- Working examples analyzed
- Corrected kernel templates created

‚ùå **What's Blocking**:
- Python mlir-aie module dependencies incomplete
- Cannot run full `aiecc.py` compilation pipeline
- C++ kernel compilation not set up

üéØ **Next Step**: Install complete mlir-aie Python package (30 min fix)

---

## Key Findings

### 1. Device Configuration ‚úÖ RESOLVED

**WRONG**: `aie.device(npu1_4col)` ‚ùå
**CORRECT**: `aie.device(npu1)` or `aie.device(npu1_1col)` ‚úÖ

Phoenix NPU is a 4√ó6 tile array with:
- 4 columns (0-3)
- Rows 2-5: Compute tiles
- Row 1: Memory tiles
- Row 0: Shim tiles (DMA)

### 2. Modern MLIR-AIE Syntax ‚úÖ FIXED

**OLD Syntax** (Our original kernels):
```mlir
aie.device(npu1_4col) {  // ‚ùå Not supported
  %buf0 = aie.buffer(%tile02) : memref<1024xi32>
  %lock0 = aie.lock(%tile02, 0)
  aie.dma_start(MM2S, 0, ^bd0, ^end)  // ‚ùå Wrong operation
  aie.end_bd ^end  // ‚ùå Operation doesn't exist
}
```

**NEW Syntax** (Correct):
```mlir
aie.device(npu1) {  // ‚úÖ Correct
  // Use ObjectFIFOs instead of manual buffers/locks
  aie.objectfifo @inOF(%tile00, {%tile02}, 2 : i32)
    : !aie.objectfifo<memref<512xui8>>

  // Runtime sequence for DMA
  aiex.runtime_sequence(%in : memref<512xi32>, ...) {
    aiex.npu.dma_memcpy_nd (0, 0, %in[...])
      { metadata = @inOF, id = 1 : i64 } : memref<512xi32>
  }
}
```

### 3. Compilation Pipeline

**Cannot Use**: `aie-opt` alone (incomplete - validation errors)

**Must Use**: `aiecc.py` (full pipeline)

**Problem**: `aiecc.py` requires Python dependencies:
```
ModuleNotFoundError: No module named 'aie.extras.runtime'
```

---

## Files Created

### Corrected MLIR Kernels

1. **mlir_aie2_minimal_corrected.mlir** - Fixed device name and syntax
2. **mlir_aie2_simple_test.mlir** - Based on working example
3. **mlir_aie2_minimal_1col.mlir** - Single column variant

Location: `/home/ucadmin/UC-1/Unicorn-Amanuensis/whisperx/npu/npu_optimization/`

### Documentation

1. **MLIR_COMPILATION_REPORT.md** - Complete 16-section analysis (1000+ lines)
   - Location: `/home/ucadmin/UC-1/Unicorn-Amanuensis/`
   - Contents: Hardware status, platform config, syntax fixes, compilation pipeline, blockers, roadmap

2. **This file** (COMPILATION_STATUS.md) - Quick reference

---

## Compilation Command (Once Dependencies Fixed)

```bash
# Set up environment
export PYTHONPATH=/home/ucadmin/mlir-aie-prebuilt/mlir_aie/python:$PYTHONPATH

# Compile MLIR to XCLBIN
aiecc.py --aie-generate-xclbin \
         --aie-generate-npu-insts \
         --no-compile-host \
         --no-xchesscc \
         --no-xbridge \
         --xclbin-name=whisper_npu.xclbin \
         --npu-insts-name=insts.bin \
         mlir_aie2_simple_test.mlir
```

---

## Critical Blockers

### Blocker 1: Python Dependencies (30 min fix)

**Issue**: `aie.extras.runtime` module missing

**Solutions**:
```bash
# Option A: Install from wheel
pip install /home/ucadmin/mlir-aie-prebuilt/mlir-aie.whl --force-reinstall

# Option B: Use Docker
docker pull ghcr.io/xilinx/mlir-aie:latest
docker run -it --device=/dev/accel/accel0 \
  -v /home/ucadmin/UC-1:/workspace \
  ghcr.io/xilinx/mlir-aie:latest

# Option C: Build from source
git clone https://github.com/Xilinx/mlir-aie.git
cd mlir-aie
pip install -e python/
```

### Blocker 2: C++ Kernel Compilation (1-2 hours)

**Issue**: Need Peano compiler with correct flags

**Solution**:
```bash
export PEANO_INSTALL_DIR=/path/to/peano
${PEANO_INSTALL_DIR}/bin/clang++ \
  ${PEANOWRAP2_FLAGS} \
  -DBIT_WIDTH=8 \
  -c kernel.cc -o kernel.cc.o
```

---

## Working Example Reference

**Source**: Xilinx/mlir-aie repository
**Path**: `programming_examples/basic/passthrough_kernel/`

**What It Shows**:
- Correct device name (`npu1`)
- ObjectFIFO usage
- External kernel linkage
- Runtime sequence
- Full Makefile compilation

**Download**:
```bash
git clone --depth 1 https://github.com/Xilinx/mlir-aie.git /tmp/mlir-aie
cd /tmp/mlir-aie/programming_examples/basic/passthrough_kernel
make  # Requires complete environment
```

---

## Performance Expectations

Based on NPU specifications and UC-Meeting-Ops experience:

| Component | Expected Speedup | Confidence |
|-----------|------------------|------------|
| Mel Spectrogram | 20-30x | High ‚úÖ |
| Attention | 50-100x | Medium ‚ö†Ô∏è |
| Full Pipeline | 100-200x | Medium ‚ö†Ô∏è |

**UC-Meeting-Ops Achieved**: 220x with Whisper Large-v3 ‚úÖ

---

## Recommended Approach

### Phase 1: Use IRON Python API (Modern)

Instead of writing raw MLIR:

```python
from aie.iron import Kernel, ObjectFifo, Program, Runtime, Worker
from aie.iron.device import NPU1Col1

def my_kernel(dev):
    # Define types
    data_type = np.ndarray[(512,), np.dtype[np.uint8]]

    # Create ObjectFIFOs
    of_in = ObjectFifo(data_type, name="in")
    of_out = ObjectFifo(data_type, name="out")

    # External kernel
    kernel = Kernel("myKernel", "kernel.cc.o", [data_type, data_type])

    # Worker
    def core_fn(of_in, of_out, kernel):
        elem_out = of_out.acquire(1)
        elem_in = of_in.acquire(1)
        kernel(elem_in, elem_out)
        of_in.release(1)
        of_out.release(1)

    worker = Worker(core_fn, [of_in.cons(), of_out.prod(), kernel])

    # Runtime
    rt = Runtime()
    with rt.sequence(data_type, data_type, dummy) as (inp, out, _):
        rt.start(worker)
        rt.fill(of_in.prod(), inp)
        rt.drain(of_out.cons(), out, wait=True)

    return Program(dev, rt).resolve_program(SequentialPlacer())

# Generate MLIR
dev = NPU1Col1()
print(my_kernel(dev))  # Outputs valid MLIR
```

**Advantages**:
- Type-safe
- Less error-prone
- Better toolchain integration
- Working examples available

### Phase 2: Compile to XCLBIN

```bash
python3 kernel.py > kernel.mlir
aiecc.py --aie-generate-xclbin kernel.mlir
```

### Phase 3: Execute with XRT

```python
import xrt

device = xrt.xrt_device(0)
xclbin = device.load_xclbin("kernel.xclbin")
# ... run kernel
```

---

## Timeline

**Conservative Estimate** (8 weeks):
- Week 1: Fix dependencies, validate simple kernel
- Week 2-3: Mel spectrogram kernel
- Week 4-6: Attention kernel
- Week 7: Pipeline integration
- Week 8: Testing

**Optimistic Estimate** (4-5 weeks with focus)

---

## Resources

### Documentation
- Full Report: `/home/ucadmin/UC-1/Unicorn-Amanuensis/MLIR_COMPILATION_REPORT.md`
- Xilinx MLIR-AIE: https://github.com/Xilinx/mlir-aie
- Device Docs: https://xilinx.github.io/mlir-aie/Devices.html

### Examples
- Downloaded: `/tmp/mlir-aie/programming_examples/`
- Corrected: `/home/ucadmin/UC-1/Unicorn-Amanuensis/whisperx/npu/npu_optimization/`

### Tools
- MLIR-AIE: `/home/ucadmin/mlir-aie-prebuilt/mlir_aie/`
- XRT: `/opt/xilinx/xrt/`
- NPU Device: `/dev/accel/accel0`

---

## Success Metrics

**Phase 1 Complete When**:
- ‚úÖ `aiecc.py` runs without errors
- ‚úÖ Simple test XCLBIN compiled
- ‚úÖ XRT loads XCLBIN successfully

**Production Ready When**:
- ‚úÖ Full Whisper pipeline on NPU
- ‚úÖ 100-200x realtime achieved
- ‚úÖ WER within 1-2% of CPU
- ‚úÖ Stable under load

---

**Status**: Ready for Phase 1 (Environment Setup)
**Blocker Resolution**: 30 minutes (Python dependencies)
**Next Reviewer**: Check if mlir-aie.whl contains full package
