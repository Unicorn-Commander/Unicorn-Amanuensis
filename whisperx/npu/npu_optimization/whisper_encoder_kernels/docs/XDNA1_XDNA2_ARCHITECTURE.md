# XDNA1/XDNA2 Architecture and Separation Strategy

**Date**: November 17, 2025
**Version**: 1.0
**Authors**: NPU Documentation Team
**Target**: NPU Whisper Encoder Optimization Project

---

## Executive Summary

This document describes the architectural separation strategy for XDNA1 (Phoenix NPU) and XDNA2 (Strix NPU) hardware platforms, designed to achieve **95% code reuse** while maximizing performance on each generation.

### Quick Facts

| Aspect | XDNA1 (Phoenix) | XDNA2 (Strix) |
|--------|-----------------|---------------|
| **NPU Generation** | 1st Gen (2023-2024) | 2nd Gen (2024+) |
| **Column Count** | 4 columns | 8 columns (2x) |
| **Performance** | 16 TOPS INT8 | 32+ TOPS INT8 (2x+) |
| **Memory Bandwidth** | ~25.6 GB/s | ~51.2 GB/s (2x) |
| **Tile Array** | 4x6 (24 tiles) | 8x6 (48 tiles) |
| **Current Hardware** | âœ… Available today | ğŸ”œ Future hardware |
| **Code Reuse** | Baseline (100%) | **95% shared with XDNA1** |

### Strategic Goals

1. **Immediate**: Optimize kernels for XDNA1 (current hardware)
2. **Portability**: Maintain 95% code reuse between generations
3. **Future-Proof**: Prepare for XDNA2 with minimal changes
4. **Performance**: Achieve near-linear scaling on XDNA2 (1.8-2x)

---

## Table of Contents

1. [Hardware Architecture Comparison](#hardware-architecture-comparison)
2. [Directory Structure](#directory-structure)
3. [Separation Strategy](#separation-strategy)
4. [Portability Approach](#portability-approach)
5. [API Design](#api-design)
6. [Performance Scaling](#performance-scaling)
7. [Migration Path](#migration-path)

---

## Hardware Architecture Comparison

### XDNA1 (Phoenix NPU) - Current Hardware

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      XDNA1 Phoenix NPU                          â”‚
â”‚                   4 Columns Ã— 6 Rows = 24 Tiles                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚   Column 0    Column 1    Column 2    Column 3                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”                â”‚
â”‚   â”‚ Mem  â”‚    â”‚ Mem  â”‚    â”‚ Mem  â”‚    â”‚ Mem  â”‚   Row 0        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜   (Memory)     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”                â”‚
â”‚   â”‚ Mem  â”‚    â”‚ Mem  â”‚    â”‚ Mem  â”‚    â”‚ Mem  â”‚   Row 1        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜   (Memory)     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”                â”‚
â”‚   â”‚ AIE  â”‚    â”‚ AIE  â”‚    â”‚ AIE  â”‚    â”‚ AIE  â”‚   Row 2        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜   (Compute)    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”                â”‚
â”‚   â”‚ AIE  â”‚    â”‚ AIE  â”‚    â”‚ AIE  â”‚    â”‚ AIE  â”‚   Row 3        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜   (Compute)    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”                â”‚
â”‚   â”‚ AIE  â”‚    â”‚ AIE  â”‚    â”‚ AIE  â”‚    â”‚ AIE  â”‚   Row 4        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜   (Compute)    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”                â”‚
â”‚   â”‚ Shim â”‚    â”‚ Shim â”‚    â”‚ Shim â”‚    â”‚ Shim â”‚   Row 5        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜   (Interface)  â”‚
â”‚                                                                  â”‚
â”‚   Performance: 16 TOPS INT8 (4 TOPS per column)                â”‚
â”‚   Bandwidth: 25.6 GB/s shared memory                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Characteristics**:
- 4 independent columns for parallel execution
- 16 compute tiles (AIE cores)
- 8 memory tiles (L2 cache)
- 4 shim tiles (DMA/host interface)
- Limited to 4-way parallelism for wide operations

### XDNA2 (Strix NPU) - Future Hardware

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           XDNA2 Strix NPU                                        â”‚
â”‚                      8 Columns Ã— 6 Rows = 48 Tiles                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                   â”‚
â”‚   Col 0   Col 1   Col 2   Col 3   Col 4   Col 5   Col 6   Col 7               â”‚
â”‚   â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”              â”‚
â”‚   â”‚Mem â”‚  â”‚Mem â”‚  â”‚Mem â”‚  â”‚Mem â”‚  â”‚Mem â”‚  â”‚Mem â”‚  â”‚Mem â”‚  â”‚Mem â”‚  Row 0       â”‚
â”‚   â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  (Memory)    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”              â”‚
â”‚   â”‚Mem â”‚  â”‚Mem â”‚  â”‚Mem â”‚  â”‚Mem â”‚  â”‚Mem â”‚  â”‚Mem â”‚  â”‚Mem â”‚  â”‚Mem â”‚  Row 1       â”‚
â”‚   â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  (Memory)    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”              â”‚
â”‚   â”‚AIE â”‚  â”‚AIE â”‚  â”‚AIE â”‚  â”‚AIE â”‚  â”‚AIE â”‚  â”‚AIE â”‚  â”‚AIE â”‚  â”‚AIE â”‚  Row 2       â”‚
â”‚   â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  (Compute)   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”              â”‚
â”‚   â”‚AIE â”‚  â”‚AIE â”‚  â”‚AIE â”‚  â”‚AIE â”‚  â”‚AIE â”‚  â”‚AIE â”‚  â”‚AIE â”‚  â”‚AIE â”‚  Row 3       â”‚
â”‚   â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  (Compute)   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”              â”‚
â”‚   â”‚AIE â”‚  â”‚AIE â”‚  â”‚AIE â”‚  â”‚AIE â”‚  â”‚AIE â”‚  â”‚AIE â”‚  â”‚AIE â”‚  â”‚AIE â”‚  Row 4       â”‚
â”‚   â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  (Compute)   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”              â”‚
â”‚   â”‚Shimâ”‚  â”‚Shimâ”‚  â”‚Shimâ”‚  â”‚Shimâ”‚  â”‚Shimâ”‚  â”‚Shimâ”‚  â”‚Shimâ”‚  â”‚Shimâ”‚  Row 5       â”‚
â”‚   â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  (Interface) â”‚
â”‚                                                                                   â”‚
â”‚   Performance: 32+ TOPS INT8 (4 TOPS per column)                                â”‚
â”‚   Bandwidth: 51.2 GB/s shared memory (2x XDNA1)                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Characteristics**:
- 8 independent columns for parallel execution (2x XDNA1)
- 32 compute tiles (AIE cores) - 2x XDNA1
- 16 memory tiles (L2 cache) - 2x XDNA1
- 8 shim tiles (DMA/host interface) - 2x XDNA1
- Enhanced 8-way parallelism for wide operations

### Architectural Differences Summary

| Feature | XDNA1 | XDNA2 | Impact |
|---------|-------|-------|--------|
| **Columns** | 4 | 8 | 2x parallel kernel launches |
| **Compute Tiles** | 16 | 32 | 2x total compute capacity |
| **Memory Tiles** | 8 | 16 | 2x L2 cache capacity |
| **Shim Tiles** | 4 | 8 | 2x DMA bandwidth |
| **Max Parallel Ops** | 4-way | 8-way | Wider matmul/attention |
| **MLIR Device** | `npu1` | `npu2` | Device target change |
| **API Changes** | IRON v1 | IRON v2 | Enhanced API |

---

## Directory Structure

### Proposed Organization

```
whisper_encoder_kernels/
â”‚
â”œâ”€â”€ docs/                                    â† NEW: Centralized documentation
â”‚   â”œâ”€â”€ README.md                            â† Index of all docs
â”‚   â”œâ”€â”€ XDNA1_XDNA2_ARCHITECTURE.md         â† This document
â”‚   â”œâ”€â”€ XDNA2_INTEGRATION_ROADMAP.md        â† Integration timeline
â”‚   â”œâ”€â”€ KERNEL_COMPARISON_XDNA1_XDNA2.md    â† Performance comparison
â”‚   â”œâ”€â”€ QUICK_START_XDNA1_XDNA2.md          â† Developer quick start
â”‚   â”œâ”€â”€ PHASE1_XDNA2_INTEGRATION_ADDENDUM.md â† Phase 1 updates
â”‚   â””â”€â”€ PORTABILITY_CHECKLIST.md            â† Code review guidelines
â”‚
â”œâ”€â”€ kernels/                                 â† Kernel implementations
â”‚   â”œâ”€â”€ common/                              â† Shared code (95%)
â”‚   â”‚   â”œâ”€â”€ attention_int8.c                 â† AIE C++ kernel (shared)
â”‚   â”‚   â”œâ”€â”€ matmul_int8.c                    â† Matrix multiply (shared)
â”‚   â”‚   â”œâ”€â”€ gelu_int8.c                      â† GELU activation (shared)
â”‚   â”‚   â”œâ”€â”€ layernorm_int8.c                 â† Layer norm (shared)
â”‚   â”‚   â”œâ”€â”€ kernel_common.h                  â† Common definitions
â”‚   â”‚   â””â”€â”€ README.md                        â† Shared kernel docs
â”‚   â”‚
â”‚   â”œâ”€â”€ xdna1/                               â† XDNA1-specific (5%)
â”‚   â”‚   â”œâ”€â”€ attention_xdna1.mlir             â† 4-column MLIR
â”‚   â”‚   â”œâ”€â”€ matmul_xdna1.mlir                â† 4-column MLIR
â”‚   â”‚   â”œâ”€â”€ gelu_xdna1.mlir                  â† 4-column MLIR
â”‚   â”‚   â”œâ”€â”€ layernorm_xdna1.mlir             â† 4-column MLIR
â”‚   â”‚   â”œâ”€â”€ platform_config.h                â† XDNA1 tile layout
â”‚   â”‚   â””â”€â”€ compile_xdna1.sh                 â† XDNA1 build script
â”‚   â”‚
â”‚   â””â”€â”€ xdna2/                               â† XDNA2-specific (5%)
â”‚       â”œâ”€â”€ attention_xdna2.mlir             â† 8-column MLIR
â”‚       â”œâ”€â”€ matmul_xdna2.mlir                â† 8-column MLIR
â”‚       â”œâ”€â”€ gelu_xdna2.mlir                  â† 8-column MLIR
â”‚       â”œâ”€â”€ layernorm_xdna2.mlir             â† 8-column MLIR
â”‚       â”œâ”€â”€ platform_config.h                â† XDNA2 tile layout
â”‚       â””â”€â”€ compile_xdna2.sh                 â† XDNA2 build script
â”‚
â”œâ”€â”€ runtime/                                 â† Runtime wrappers
â”‚   â”œâ”€â”€ common/                              â† Shared runtime (95%)
â”‚   â”‚   â”œâ”€â”€ npu_base.py                      â† Base NPU class
â”‚   â”‚   â”œâ”€â”€ buffer_manager.py                â† Buffer allocation
â”‚   â”‚   â”œâ”€â”€ kernel_loader.py                 â† XCLBIN loading
â”‚   â”‚   â””â”€â”€ performance_monitor.py           â† Profiling tools
â”‚   â”‚
â”‚   â”œâ”€â”€ xdna1/                               â† XDNA1 runtime (5%)
â”‚   â”‚   â”œâ”€â”€ npu_xdna1.py                     â† XDNA1 NPU class
â”‚   â”‚   â”œâ”€â”€ npu_attention_wrapper.py         â† Attention wrapper
â”‚   â”‚   â””â”€â”€ npu_matmul_wrapper.py            â† MatMul wrapper
â”‚   â”‚
â”‚   â””â”€â”€ xdna2/                               â† XDNA2 runtime (5%)
â”‚       â”œâ”€â”€ npu_xdna2.py                     â† XDNA2 NPU class
â”‚       â”œâ”€â”€ npu_attention_wrapper.py         â† Attention wrapper
â”‚       â””â”€â”€ npu_matmul_wrapper.py            â† MatMul wrapper
â”‚
â”œâ”€â”€ build/                                   â† Build outputs
â”‚   â”œâ”€â”€ xdna1/                               â† XDNA1 XCLBINs
â”‚   â”‚   â”œâ”€â”€ attention_64x64.xclbin
â”‚   â”‚   â”œâ”€â”€ matmul_32x32.xclbin
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â””â”€â”€ xdna2/                               â† XDNA2 XCLBINs (future)
â”‚       â”œâ”€â”€ attention_128x64.xclbin
â”‚       â”œâ”€â”€ matmul_64x64.xclbin
â”‚       â””â”€â”€ ...
â”‚
â””â”€â”€ tests/                                   â† Test suites
    â”œâ”€â”€ common/                              â† Shared tests
    â”‚   â”œâ”€â”€ test_attention_accuracy.py
    â”‚   â”œâ”€â”€ test_matmul_accuracy.py
    â”‚   â””â”€â”€ benchmark_suite.py
    â”‚
    â”œâ”€â”€ xdna1/
    â”‚   â””â”€â”€ test_xdna1_kernels.py
    â”‚
    â””â”€â”€ xdna2/
        â””â”€â”€ test_xdna2_kernels.py
```

### Migration Path from Current Structure

**Current Structure** (everything in root):
```
whisper_encoder_kernels/
â”œâ”€â”€ attention_int8_64x64.c                   â† Move to kernels/common/
â”œâ”€â”€ matmul_int8_32x32.c                      â† Move to kernels/common/
â”œâ”€â”€ attention_64x64.mlir                     â† Move to kernels/xdna1/
â”œâ”€â”€ npu_attention_wrapper.py                 â† Move to runtime/xdna1/
â””â”€â”€ ... (150+ files in root)
```

**Phase 1**: Create structure, copy files (no changes)
**Phase 2**: Update imports/paths (test thoroughly)
**Phase 3**: Refactor for portability (gradual)
**Phase 4**: Add XDNA2 variants (future)

---

## Separation Strategy

### What to Share (95% of Code)

#### 1. AIE C++ Kernel Code (100% Shared)

**Rationale**: Computational logic is identical across generations

**Files**:
- `kernels/common/attention_int8.c`
- `kernels/common/matmul_int8.c`
- `kernels/common/gelu_int8.c`
- `kernels/common/layernorm_int8.c`

**Example** - `matmul_int8.c` (fully portable):
```c
// kernels/common/matmul_int8.c
// This code works on BOTH XDNA1 and XDNA2 without changes

void matmul_int8_kernel(
    int8_t* A,      // [M x K] matrix
    int8_t* B,      // [K x N] matrix
    int8_t* C,      // [M x N] result
    int M, int K, int N
) {
    // Vectorized INT8 matrix multiply
    // Uses AIE intrinsics that work on both XDNA1 and XDNA2
    for (int i = 0; i < M; i++) {
        for (int j = 0; j < N; j++) {
            int32_t acc = 0;
            for (int k = 0; k < K; k += 32) {
                // Vector load and multiply-accumulate
                // AIE intrinsics are generation-independent
                v32int8 a_vec = *(v32int8*)&A[i*K + k];
                v32int8 b_vec = *(v32int8*)&B[k*N + j];
                acc = mac16(acc, a_vec, 0, 0x76543210, 16,
                           b_vec, 0, 0, 2);
            }
            C[i*N + j] = quantize_int32_to_int8(acc);
        }
    }
}
```

**Key Principle**: Kernel logic is hardware-agnostic, only tile layout differs.

#### 2. Python Runtime Base Classes (95% Shared)

**Rationale**: XRT API and buffer management are mostly identical

**Files**:
- `runtime/common/npu_base.py`
- `runtime/common/buffer_manager.py`
- `runtime/common/kernel_loader.py`

**Example** - `npu_base.py`:
```python
# runtime/common/npu_base.py
import xrt

class NPUBase:
    """Base class for NPU runtime - works on XDNA1 and XDNA2"""

    def __init__(self, device_id=0):
        self.device = xrt.xrt_device(device_id)
        self.uuid = None
        self.kernels = {}

    def load_xclbin(self, xclbin_path):
        """Load compiled kernel - same API for both generations"""
        self.uuid = self.device.load_xclbin(xclbin_path)

    def allocate_buffer(self, size, bank=0):
        """Allocate device buffer - same API"""
        return xrt.xrt_bo(self.device, size, 0, bank)

    def execute_kernel(self, kernel_name, *args):
        """Execute kernel - same API"""
        kernel = self.kernels[kernel_name]
        run = kernel(*args)
        return run.wait(timeout=5000)
```

**Portability**: 95% of runtime code is device-independent.

#### 3. Test Suites and Benchmarks (100% Shared)

**Rationale**: Validation logic is the same, only performance targets differ

**Files**:
- `tests/common/test_attention_accuracy.py`
- `tests/common/test_matmul_accuracy.py`
- `tests/common/benchmark_suite.py`

### What to Separate (5% of Code)

#### 1. MLIR Platform Configuration (100% Different)

**Rationale**: Tile layout and column count are hardware-specific

**XDNA1** - `kernels/xdna1/attention_xdna1.mlir`:
```mlir
// 4 columns, 4-way parallelism
module @attention_xdna1 {
  aie.device(npu1) {  // â† XDNA1 device target

    // 4 columns available
    %tile_0_2 = aie.tile(0, 2)  // Column 0
    %tile_1_2 = aie.tile(1, 2)  // Column 1
    %tile_2_2 = aie.tile(2, 2)  // Column 2
    %tile_3_2 = aie.tile(3, 2)  // Column 3

    // 4-way parallel attention computation
    // ...
  }
}
```

**XDNA2** - `kernels/xdna2/attention_xdna2.mlir`:
```mlir
// 8 columns, 8-way parallelism
module @attention_xdna2 {
  aie.device(npu2) {  // â† XDNA2 device target

    // 8 columns available (2x XDNA1)
    %tile_0_2 = aie.tile(0, 2)  // Column 0
    %tile_1_2 = aie.tile(1, 2)  // Column 1
    %tile_2_2 = aie.tile(2, 2)  // Column 2
    %tile_3_2 = aie.tile(3, 2)  // Column 3
    %tile_4_2 = aie.tile(4, 2)  // Column 4 â† NEW
    %tile_5_2 = aie.tile(5, 2)  // Column 5 â† NEW
    %tile_6_2 = aie.tile(6, 2)  // Column 6 â† NEW
    %tile_7_2 = aie.tile(7, 2)  // Column 7 â† NEW

    // 8-way parallel attention computation
    // ...
  }
}
```

**Difference**: Only device target and tile indices change.

#### 2. Platform Configuration Headers (100% Different)

**XDNA1** - `kernels/xdna1/platform_config.h`:
```c
// XDNA1 Phoenix NPU Configuration
#define NPU_NUM_COLUMNS 4
#define NPU_NUM_ROWS 6
#define NPU_NUM_COMPUTE_TILES 16
#define NPU_DEVICE_NAME "npu1"
#define NPU_MAX_PARALLEL_OPS 4
```

**XDNA2** - `kernels/xdna2/platform_config.h`:
```c
// XDNA2 Strix NPU Configuration
#define NPU_NUM_COLUMNS 8
#define NPU_NUM_ROWS 6
#define NPU_NUM_COMPUTE_TILES 32
#define NPU_DEVICE_NAME "npu2"
#define NPU_MAX_PARALLEL_OPS 8
```

#### 3. Runtime Column Mapping (5% Different)

**XDNA1** - `runtime/xdna1/npu_xdna1.py`:
```python
class NPUXDNA1(NPUBase):
    """XDNA1-specific runtime"""

    NUM_COLUMNS = 4

    def get_tile_mapping(self, operation_width):
        """Map operation to 4 columns"""
        if operation_width <= 4:
            return list(range(operation_width))
        else:
            # Time-multiplex on 4 columns
            return self._time_multiplex(operation_width, 4)
```

**XDNA2** - `runtime/xdna2/npu_xdna2.py`:
```python
class NPUXDNA2(NPUBase):
    """XDNA2-specific runtime"""

    NUM_COLUMNS = 8

    def get_tile_mapping(self, operation_width):
        """Map operation to 8 columns"""
        if operation_width <= 8:
            return list(range(operation_width))
        else:
            # Time-multiplex on 8 columns
            return self._time_multiplex(operation_width, 8)
```

**Difference**: Only column count and mapping logic.

---

## Portability Approach

### Principle 1: Write Once, Configure Twice

**Bad** (duplicated kernel code):
```c
// DON'T DO THIS - duplicates logic
void matmul_xdna1(...) { /* 4-column implementation */ }
void matmul_xdna2(...) { /* 8-column implementation */ }
```

**Good** (shared kernel, configured layout):
```c
// kernels/common/matmul_int8.c - SINGLE IMPLEMENTATION
void matmul_int8_kernel(...) { /* portable logic */ }

// kernels/xdna1/matmul_xdna1.mlir - 4 column layout
// kernels/xdna2/matmul_xdna2.mlir - 8 column layout
```

### Principle 2: Abstract Hardware in MLIR, Not C++

**Rationale**: AIE C++ kernels are already portable, MLIR handles tile mapping

**C++ Kernel** (100% shared):
- Computational logic
- Vectorization
- Accumulation
- Quantization

**MLIR Configuration** (hardware-specific):
- Device target (`npu1` vs `npu2`)
- Tile coordinates
- Column count
- DMA patterns

### Principle 3: Runtime Detection and Fallback

**Smart Runtime**:
```python
# runtime/__init__.py - Auto-detect hardware
import xrt

def create_npu():
    """Factory function - auto-detects hardware generation"""
    device = xrt.xrt_device(0)

    # Query device properties
    device_name = device.get_info(xrt.info_device.name)

    if "Phoenix" in device_name or "XDNA1" in device_name:
        from runtime.xdna1.npu_xdna1 import NPUXDNA1
        return NPUXDNA1()
    elif "Strix" in device_name or "XDNA2" in device_name:
        from runtime.xdna2.npu_xdna2 import NPUXDNA2
        return NPUXDNA2()
    else:
        raise RuntimeError(f"Unknown NPU: {device_name}")
```

**Benefits**:
- User code doesn't change
- Automatic hardware detection
- No manual configuration needed

### Principle 4: Shared Test Suite, Different Targets

**Test Code** (100% shared):
```python
# tests/common/test_matmul_accuracy.py
def test_matmul_accuracy(npu):
    """Test matmul accuracy - works on any NPU"""
    A = np.random.randint(-32, 32, (64, 64), dtype=np.int8)
    B = np.random.randint(-32, 32, (64, 64), dtype=np.int8)

    # NPU computation
    C_npu = npu.matmul(A, B)

    # CPU reference
    C_ref = np.matmul(A.astype(np.int32), B.astype(np.int32))
    C_ref = np.clip(C_ref, -128, 127).astype(np.int8)

    # Validate
    correlation = np.corrcoef(C_npu.flat, C_ref.flat)[0, 1]
    assert correlation > 0.95, f"Low correlation: {correlation}"
```

**Test Runner** (generation-specific):
```python
# tests/xdna1/test_xdna1_kernels.py
from runtime.xdna1.npu_xdna1 import NPUXDNA1
from tests.common.test_matmul_accuracy import test_matmul_accuracy

npu = NPUXDNA1()
test_matmul_accuracy(npu)  # Same test, different hardware
```

---

## API Design

### Unified NPU Interface

**Goal**: User code works unchanged on XDNA1 or XDNA2

```python
# User code - generation-independent
from whisper_npu import create_npu

# Auto-detect hardware (XDNA1 or XDNA2)
npu = create_npu()

# Same API regardless of hardware
Q = np.random.randint(-64, 64, (1500, 64), dtype=np.int8)
K = np.random.randint(-64, 64, (1500, 64), dtype=np.int8)
V = np.random.randint(-64, 64, (1500, 64), dtype=np.int8)

# Attention computation - auto-scales to hardware
output = npu.attention(Q, K, V)
# XDNA1: Uses 4 columns
# XDNA2: Uses 8 columns (2x faster)
```

### Hardware-Specific Optimizations (Optional)

**Advanced Usage**:
```python
# Advanced: Hardware-specific tuning
npu = create_npu()

if npu.generation == "XDNA1":
    # Optimize for 4 columns
    npu.set_tile_size(64, 64)      # Balanced for 4 columns
    npu.set_batch_size(4)           # Matches column count
elif npu.generation == "XDNA2":
    # Optimize for 8 columns
    npu.set_tile_size(128, 64)      # Larger tiles for 8 columns
    npu.set_batch_size(8)           # Matches column count

output = npu.attention(Q, K, V)
```

**Benefits**:
- Default: Works without changes
- Advanced: Squeeze extra performance if needed

---

## Performance Scaling

### Expected Performance on XDNA2

**Theoretical Maximum**: 2x speedup (2x columns, 2x bandwidth)

**Realistic Targets** (accounting for overhead):

| Kernel | XDNA1 (4 col) | XDNA2 (8 col) | Speedup | Notes |
|--------|---------------|---------------|---------|-------|
| **MatMul 64x64** | 0.46 ms | 0.25 ms | 1.84x | Bandwidth-limited |
| **Attention 64x64** | 3.6 ms | 2.0 ms | 1.80x | Compute-limited |
| **GELU 2048** | 1.3 Âµs | 0.7 Âµs | 1.86x | Memory-limited |
| **LayerNorm 512** | 0.8 ms | 0.45 ms | 1.78x | Mixed |
| **Full Encoder** | 45 ms | 25 ms | 1.80x | End-to-end |

**Scaling Factors**:
- **Linear Ops** (matmul): 1.8-1.9x (near-perfect scaling)
- **Non-linear** (softmax, GELU): 1.7-1.8x (memory overhead)
- **Control Flow**: 1.5-1.7x (synchronization overhead)

### Why Not Perfect 2x?

**Bottlenecks**:
1. **Host-Device Transfer**: Same PCIe bandwidth
2. **Synchronization**: More columns = more synchronization points
3. **Memory Contention**: Shared memory tiles
4. **Amdahl's Law**: Some serial components remain

**Optimization Strategies for XDNA2**:
1. Larger tile sizes (128x64 vs 64x64)
2. Better column utilization (8-way vs 4-way)
3. Reduced kernel launches (batch more work)
4. Pipelined execution across columns

---

## Migration Path

### Phase 1: Organize Current Code (Week 1)

**Actions**:
1. Create `kernels/common/`, `kernels/xdna1/` directories
2. Copy C++ kernels to `kernels/common/` (no changes)
3. Copy MLIR to `kernels/xdna1/`
4. Create `runtime/xdna1/` with current wrappers
5. Update imports/paths

**Testing**: Everything should work exactly as before

**Risk**: Low (just file moves)

### Phase 2: Add IRON API (Week 2)

**Actions**:
1. Migrate MLIR from manual DMA to IRON ObjectFIFO
2. Update compilation scripts
3. Test on XDNA1 hardware
4. Document changes

**Testing**: Verify kernels still work, measure any performance change

**Risk**: Medium (API change, but IRON is more robust)

### Phase 3: Prepare XDNA2 Directory Structure (Week 3)

**Actions**:
1. Create `kernels/xdna2/` (empty initially)
2. Create `runtime/xdna2/` (skeleton code)
3. Add platform detection
4. Document XDNA2 plans

**Testing**: N/A (no XDNA2 hardware yet)

**Risk**: Low (no execution changes)

### Phase 4: XDNA2 Kernel Development (When Hardware Available)

**Actions**:
1. Copy MLIR from `xdna1/` to `xdna2/`
2. Update device target: `npu1` â†’ `npu2`
3. Update tile coordinates: 4 columns â†’ 8 columns
4. Compile and test on XDNA2 hardware
5. Benchmark and optimize

**Testing**: Run full test suite on XDNA2

**Risk**: Medium (new hardware, needs validation)

---

## Code Reuse Breakdown

### 95% Shared Components

**Category** | **Files** | **Lines of Code** | **Shared %**
---|---|---|---
**AIE C++ Kernels** | 8 files | 2,500 LOC | 100%
**Python Runtime Base** | 6 files | 1,800 LOC | 95%
**Test Suite** | 12 files | 3,200 LOC | 100%
**Documentation** | 10 files | 8,000 LOC | 100%
**Build Scripts** | 4 files | 400 LOC | 80%
**Utilities** | 5 files | 600 LOC | 100%

**Total Shared**: ~16,500 LOC (95%)

### 5% Hardware-Specific Components

**Category** | **Files** | **Lines of Code** | **Variants**
---|---|---|---
**MLIR Platform** | 8 files | 600 LOC | XDNA1, XDNA2
**Platform Config** | 2 files | 50 LOC | XDNA1, XDNA2
**Runtime Mapping** | 2 files | 150 LOC | XDNA1, XDNA2
**Build Configs** | 2 files | 50 LOC | XDNA1, XDNA2

**Total Hardware-Specific**: ~850 LOC (5%)

**Total Project Size**: ~17,350 LOC

---

## Summary

### Key Takeaways

1. **95% code reuse is achievable** between XDNA1 and XDNA2
2. **AIE C++ kernels are 100% portable** - no changes needed
3. **MLIR handles all hardware differences** - device target and tile layout
4. **Runtime auto-detects hardware** - user code unchanged
5. **Expected 1.8-2x speedup on XDNA2** - near-linear scaling

### Strategic Benefits

**For Development**:
- Write kernels once, target two generations
- Reduce maintenance burden
- Easier testing and validation
- Clear migration path

**For Performance**:
- Immediate optimization on XDNA1 (current hardware)
- Future-proof for XDNA2 (automatic scaling)
- No performance compromises for portability
- Best-of-breed on each generation

**For PM/Decision-Making**:
- Clear ROI: 95% code reuse
- Low risk: Proven on XDNA1 first
- Predictable timeline: 4-phase roadmap
- Future-proof: Ready for XDNA2 day one

---

**Document Version**: 1.0
**Last Updated**: November 17, 2025
**Next Review**: After Phase 2 (IRON API migration)
**Maintained By**: NPU Documentation Team
