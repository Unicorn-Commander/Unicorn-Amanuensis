# Files Created During Multi-Core Investigation

**Date**: October 29, 2025  
**Investigation Time**: ~15 minutes  
**Total Files Created**: 5

---

## Documentation Files

### 1. INVESTIGATION_SUMMARY.md
**Purpose**: Quick reference for key findings  
**Size**: ~3KB  
**Content**: 
- TL;DR of investigation
- Key discoveries
- Recommended approaches
- Next actions

### 2. MULTICORE_COMPILATION_GUIDE.md  
**Purpose**: Comprehensive technical guide  
**Size**: ~12KB  
**Content**:
- Detailed findings
- Chess toolchain status
- Working compilation flow
- Multi-core challenges
- Environment setup
- Performance expectations
- Complete next steps

### 3. FILES_CREATED.md (this file)
**Purpose**: Index of all created files  
**Content**: List and description of investigation outputs

---

## Scripts

### 4. compile_attention_multicore.sh
**Purpose**: Multi-core compilation script (has issues)  
**Status**: ⚠️ Fails with lock domination error  
**Size**: ~2KB  
**Usage**: 
```bash
bash compile_attention_multicore.sh
# Currently fails - needs IRON API
```
**Kept for**: Future reference when implementing IRON

### 5. verify_toolchain.sh
**Purpose**: Toolchain verification script  
**Status**: ✅ Working  
**Size**: ~2KB  
**Usage**:
```bash
bash verify_toolchain.sh
# Checks all tools and compiles test kernel
```
**Output**:
- Verifies Peano compiler
- Verifies MLIR-AIE tools
- Verifies XRT runtime
- Tests single-core compilation
- Reports status of all components

---

## Existing Files Referenced

### Working Compilation Scripts (already existed)
1. `compile_attention_64x64.sh` - Single-core attention (working)
2. `compile_layernorm.sh` - LayerNorm kernel (working)
3. `compile_matmul_simple.sh` - Matrix multiplication (working)

### MLIR Designs
1. `attention_64x64.mlir` - Single-core attention (working)
2. `attention_64x64_multicore.mlir` - Multi-core (has lock issues)
3. `layernorm_simple.mlir` - LayerNorm (working)
4. `matmul_simple.mlir` - MatMul (working)

### C Kernels
1. `attention_int8_64x64_tiled.c` - Attention implementation
2. `layernorm_int8.c` - LayerNorm implementation
3. `matmul_int8.c` - MatMul implementation

### Build Outputs (generated by scripts)
1. `build_attention_64x64/attention_64x64.xclbin` (12KB)
2. `build_attention_64x64/insts.bin` (300 bytes)
3. `build_layernorm/layernorm_simple.xclbin` (10KB)
4. `build/matmul_simple.xclbin` (varies)

---

## File Locations

All files in:
```
/home/ucadmin/UC-1/Unicorn-Amanuensis/whisperx/npu/npu_optimization/whisper_encoder_kernels/
```

**Directory structure**:
```
whisper_encoder_kernels/
├── Documentation (NEW)
│   ├── INVESTIGATION_SUMMARY.md           # Quick reference
│   ├── MULTICORE_COMPILATION_GUIDE.md     # Detailed guide
│   └── FILES_CREATED.md                   # This file
│
├── Scripts (NEW)
│   ├── compile_attention_multicore.sh     # Multi-core (issues)
│   └── verify_toolchain.sh                # Verification
│
├── Working Scripts (existing)
│   ├── compile_attention_64x64.sh         # Single-core attention
│   ├── compile_layernorm.sh               # LayerNorm
│   └── compile_matmul_simple.sh           # MatMul
│
├── MLIR Designs
│   ├── attention_64x64.mlir               # Working single-core
│   ├── attention_64x64_multicore.mlir     # Multi-core (issues)
│   ├── layernorm_simple.mlir              # Working
│   └── matmul_simple.mlir                 # Working
│
├── C Kernels
│   ├── attention_int8_64x64_tiled.c
│   ├── layernorm_int8.c
│   └── matmul_int8.c
│
└── Build Outputs
    ├── build_attention_64x64/
    │   ├── attention_64x64.xclbin         # 12KB NPU binary
    │   └── insts.bin                      # 300 bytes
    ├── build_layernorm/
    │   └── layernorm_simple.xclbin        # 10KB
    └── build/
        └── matmul_simple.xclbin
```

---

## Key Findings Documented

### 1. Chess Compiler Status
- **NOT REQUIRED** for basic compilation
- All working kernels use `--no-xchesscc`
- Peano compiler used instead

### 2. Toolchain Location
- Peano: `/home/ucadmin/mlir-aie-fresh/mlir-aie/venv313/lib/python3.13/site-packages/llvm-aie`
- MLIR-AIE: `/home/ucadmin/mlir-aie-fresh/mlir-aie/venv313/bin/`
- XRT: `/opt/xilinx/xrt/`

### 3. Working Compilation Flow
```bash
# 1. Compile C kernel
clang --target=aie2-none-unknown-elf -c kernel.c -o kernel.o

# 2. Create archive
llvm-ar rcs combined.o kernel.o

# 3. Generate XCLBIN
aiecc.py --no-xchesscc --no-xbridge design.mlir
```

### 4. Multi-Core Challenges
- Hand-written MLIR has lock synchronization issues
- Solution: Use Python IRON API
- Workaround: Batched single-core execution

### 5. Recommended Path
- **Today**: Use batched single-core
- **1-2 weeks**: Implement IRON API for true parallel
- **Expected**: 4× throughput with multi-core

---

## How to Use This Investigation

### If You Need Quick Answers:
Read: `INVESTIGATION_SUMMARY.md`

### If You Need Technical Details:
Read: `MULTICORE_COMPILATION_GUIDE.md`

### If You Want to Verify Toolchain:
Run: `bash verify_toolchain.sh`

### If You Want to Test Compilation:
Run: `bash compile_attention_64x64.sh` (working)

### If You Want to Try Multi-Core:
Study: `/home/ucadmin/mlir-aie-fresh/mlir-aie/programming_examples/basic/matrix_multiplication/whole_array/whole_array_iron.py`

---

## Questions Answered

1. ✅ **Is chess toolchain available?**  
   Yes, but not needed. Use `--no-xchesscc`.

2. ✅ **Where is it located?**  
   Peano compiler in mlir-aie venv, chess wrapper available but unused.

3. ✅ **How were existing XCLBINs compiled?**  
   Using Peano clang + aiecc.py with `--no-xchesscc --no-xbridge`.

4. ✅ **What's the recommended compilation approach?**  
   Use existing scripts for single-core, IRON API for multi-core.

5. ✅ **Can we proceed with multi-core today?**  
   Yes, using batched single-core. True parallel needs IRON API (1-2 weeks).

---

## Time Investment

- **Investigation**: ~15 minutes
- **Documentation**: 5 files, ~20KB total
- **Scripts Created**: 2 (multicore + verification)
- **Verification**: All tools checked and tested

---

## Next Steps

See `INVESTIGATION_SUMMARY.md` for immediate actions and `MULTICORE_COMPILATION_GUIDE.md` for detailed roadmap.

---

**Investigation Complete** ✅  
**All Questions Answered** ✅  
**Toolchain Verified** ✅  
**Path Forward Clear** ✅
