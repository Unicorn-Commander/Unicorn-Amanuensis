# NPU Matmul Integration - Quick Start Guide

**Date**: October 30, 2025
**Status**: Ready for Implementation

---

## TL;DR

**What**: Integrate 16Ã—16 NPU matmul kernel into Whisper encoder/decoder
**Why**: Improve performance from 19.1Ã— to 25-29Ã— realtime
**How**: Use NPUMatmul wrapper class (already created)
**When**: 1.5 days to production (11 hours remaining)

---

## Quick Commands

### Test the Wrapper
```bash
cd /home/ucadmin/UC-1/Unicorn-Amanuensis/whisperx/npu/npu_optimization/whisper_encoder_kernels
python3 npu_matmul_wrapper.py
```

### Example Usage
```python
from npu_matmul_wrapper import NPUMatmul
import numpy as np

# Initialize (once)
matmul = NPUMatmul()

# Use it
A = np.random.randint(-64, 64, (512, 512), dtype=np.int8)
B = np.random.randint(-64, 64, (512, 512), dtype=np.int8)
C = matmul(A, B)  # Handles tiling automatically

# Check stats
print(matmul.get_stats())
```

---

## What's Been Delivered

### Code (728 lines)
âœ… `/home/ucadmin/UC-1/Unicorn-Amanuensis/whisperx/npu/npu_optimization/whisper_encoder_kernels/npu_matmul_wrapper.py`

**Features**:
- Handles arbitrary matrix sizes (auto-tiling)
- INT8 quantization (FP32â†’INT8)
- Thread-safe (for multi-threaded server)
- Batch processing support
- Performance tracking

### Documentation (2,000+ lines)

âœ… `MATMUL_INTEGRATION_PLAN.md` (1,262 lines)
- Complete integration plan
- File-by-file changes
- Test framework design
- Performance expectations

âœ… `NPU_MATMUL_INTEGRATION_COMPLETE.md` (1,700+ lines)
- Comprehensive delivery report
- Matmul usage analysis (90 operations)
- Risk assessment
- Implementation timeline

âœ… `MATMUL_QUICK_START.md` (this file)
- Quick reference
- Essential commands
- Next steps

### Analysis

âœ… **Matmul Usage Analysis**:
- 90 total operations (48 encoder + 42 decoder)
- 109.4B FLOPs total
- 15-20% of total compute
- All in critical path

âœ… **Performance Projections**:
- Optimistic: 29Ã— realtime (+52%)
- Realistic: 25Ã— realtime (+31%)
- Conservative: 22Ã— realtime (+15%)

---

## What's Next (11 Hours)

### Phase 2: Unit Tests (2 hours)
```bash
# Create test file
touch test_npu_matmul_wrapper.py

# Implement 10 test cases:
# 1. test_small_matrix()
# 2. test_large_matrix()
# 3. test_non_square()
# 4. test_non_multiple_16()
# 5. test_batch_processing()
# 6. test_quantization()
# 7. test_thread_safety()
# 8. test_error_handling()
# 9. test_edge_cases()
# 10. test_statistics()

# Run tests
pytest test_npu_matmul_wrapper.py -v
```

### Phase 3: Encoder Integration (3 hours)
```python
# Create whisper_npu_encoder.py
from npu_matmul_wrapper import NPUMatmul

class NPUWhisperEncoder:
    def __init__(self):
        self.matmul = NPUMatmul()

    def attention_qkv_projection(self, x, W_q, W_k, W_v):
        Q = self.matmul(x, W_q)  # Replace torch.matmul
        K = self.matmul(x, W_k)
        V = self.matmul(x, W_v)
        return Q, K, V

    def ffn_layers(self, x, W1, W2):
        hidden = self.matmul(x, W1)  # Replace torch.matmul
        hidden = gelu(hidden)
        output = self.matmul(hidden, W2)  # Replace torch.matmul
        return output
```

### Phase 4: Decoder Integration (3 hours)
```python
# Create whisper_npu_decoder.py
from npu_matmul_wrapper import NPUMatmul

class NPUWhisperDecoder:
    def __init__(self):
        self.matmul = NPUMatmul()

    def self_attention(self, x, W_q, W_k, W_v):
        Q = self.matmul(x, W_q)
        K = self.matmul(x, W_k)
        V = self.matmul(x, W_v)
        return Q, K, V

    def cross_attention(self, x, encoder_output, W_k, W_v):
        K = self.matmul(encoder_output, W_k)
        V = self.matmul(encoder_output, W_v)
        return K, V
```

### Phase 5: End-to-End Testing (2 hours)
```python
# Test full pipeline
def test_full_transcription():
    audio_path = "test_audio.wav"

    # With NPU matmul
    stt_npu = UnifiedSTTDiarization(use_npu=True)
    result_npu = stt_npu.transcribe(audio_path)

    # Verify performance
    assert result_npu['realtime_factor'] >= 25  # Target: 25-29Ã—

    # Verify accuracy
    assert result_npu['wer_increase_pct'] < 1  # <1% WER increase
```

### Phase 6: Production Deployment (1 hour)
```python
# Update server_production.py
import os
from npu_matmul_wrapper import NPUMatmul

if os.getenv("WHISPER_NPU_MATMUL") == "1":
    from whisper_npu_encoder import NPUWhisperEncoder
    from whisper_npu_decoder import NPUWhisperDecoder

    encoder = NPUWhisperEncoder()
    decoder = NPUWhisperDecoder()
else:
    # Fallback to CPU/ONNX
    pass
```

---

## Key Performance Targets

| Metric | Target | Current | Status |
|--------|--------|---------|--------|
| Per-tile latency | 0.484ms | 0.484ms | âœ… |
| 512Ã—512 matrix | <500ms | ~496ms | âœ… |
| Full transcription | 25-29Ã— realtime | 19.1Ã— | â° |
| WER increase | <1% | TBD | â° |
| Correlation | >0.999 | 1.000 | âœ… |

---

## Troubleshooting

### NPU Device Not Found
```bash
# Check device
ls -l /dev/accel/accel0

# Check XRT
/opt/xilinx/xrt/bin/xrt-smi examine
```

### Import Error
```python
# Check pyxrt
python3 -c "import sys; sys.path.insert(0, '/opt/xilinx/xrt/python'); import pyxrt; print('OK')"
```

### Kernel Not Found
```bash
# Check xclbin exists
ls -l build_matmul_fixed/matmul_16x16.xclbin
ls -l build_matmul_fixed/main_sequence.bin
```

### Performance Issues
```python
# Check statistics
from npu_matmul_wrapper import NPUMatmul
matmul = NPUMatmul()
# ... use matmul ...
stats = matmul.get_stats()
print(f"Avg time per tile: {stats['avg_time_per_tile_ms']:.3f}ms")
print(f"Tiles per second: {stats['tiles_per_second']:.0f}")
```

---

## Environment Variables

```bash
# Enable NPU matmul
export WHISPER_NPU_MATMUL=1

# Specify xclbin path (optional, auto-detected)
export NPU_MATMUL_XCLBIN=/path/to/matmul_16x16.xclbin

# Enable CPU fallback
export WHISPER_NPU_FALLBACK=1

# Debug mode
export NPU_MATMUL_DEBUG=1
```

---

## Files and Locations

**Working Kernel**:
- `build_matmul_fixed/matmul_16x16.xclbin` (11 KB)
- `build_matmul_fixed/main_sequence.bin` (300 bytes)

**Code**:
- `npu_matmul_wrapper.py` (728 lines) âœ…

**Documentation**:
- `MATMUL_INTEGRATION_PLAN.md` (1,262 lines) âœ…
- `NPU_MATMUL_INTEGRATION_COMPLETE.md` (1,700+ lines) âœ…
- `MATMUL_QUICK_START.md` (this file) âœ…

**Tests** (to create):
- `test_npu_matmul_wrapper.py`
- `test_npu_encoder_integration.py`
- `test_npu_decoder_integration.py`
- `test_end_to_end.py`

**Integration** (to create):
- `whisper_npu_encoder.py`
- `whisper_npu_decoder.py`

---

## Expected Timeline

| Phase | Task | Time | Status |
|-------|------|------|--------|
| 1 | Wrapper development | 4 hours | âœ… DONE |
| 2 | Unit tests | 2 hours | â° Next |
| 3 | Encoder integration | 3 hours | â° Pending |
| 4 | Decoder integration | 3 hours | â° Pending |
| 5 | End-to-end testing | 2 hours | â° Pending |
| 6 | Production deployment | 1 hour | â° Pending |
| **Total** | | **15 hours** | **4 done, 11 remaining** |

**Schedule**:
- Day 1 (Today): Phases 2-3 = 5 hours
- Day 2 (Tomorrow): Phases 4-6 = 6 hours

---

## Success Criteria

**Functional** âœ…:
- âœ… NPU matmul wrapper handles arbitrary sizes
- â° Encoder uses NPU matmul
- â° Decoder uses NPU matmul
- â° Thread-safe operation
- â° Graceful CPU fallback

**Performance** âœ…/â°:
- âœ… Per-tile: 0.484ms
- â° End-to-end: 25-29Ã— realtime
- â° Throughput: >2,000 tiles/s

**Accuracy** âœ…/â°:
- âœ… Correlation: >0.999
- â° WER increase: <1%
- â° Quantization error: <1%

---

## Path to 220Ã— Realtime

| Phase | Components | Performance | Timeline |
|-------|------------|-------------|----------|
| **Now** | DMA pipelining | 19.1Ã— | âœ… Done |
| **Today** | + 16Ã—16 matmul + mel | 25-29Ã— | ğŸ¯ This task |
| **Week 1** | + GELU + LayerNorm | 30-35Ã— | â° Next |
| **Week 2** | + Attention (debug) | 60-80Ã— | â° After |
| **Month 1** | + 32Ã—32/64Ã—64 tiles | 100-120Ã— | â° Future |
| **Month 2** | Full encoder on NPU | 150-180Ã— | â° Future |
| **Month 3** | Full decoder on NPU | **220Ã—** | ğŸ¯ Target |

---

## Contact & Support

**Documentation**:
- Read `MATMUL_INTEGRATION_PLAN.md` for detailed plan
- Read `NPU_MATMUL_INTEGRATION_COMPLETE.md` for full report
- Read `WORKING_KERNELS_INVENTORY_OCT30.md` for kernel details

**Testing**:
- Run self-test: `python3 npu_matmul_wrapper.py`
- Run benchmarks: Check wrapper code for `benchmark()` method
- Check statistics: Use `get_stats()` method

**Issues**:
- Check NPU device: `/dev/accel/accel0`
- Check XRT: `xrt-smi examine`
- Check logs for errors

---

**Quick Start Created**: October 30, 2025
**Status**: âœ… Ready for Implementation
**Next Step**: Phase 2 (Unit Tests) - 2 hours
