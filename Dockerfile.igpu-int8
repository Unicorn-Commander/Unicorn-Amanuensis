FROM python:3.10-slim

# Install system dependencies
RUN apt-get update && apt-get install -y \
    ffmpeg \
    git \
    curl \
    wget \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Install Python dependencies for OpenVINO
RUN pip install --no-cache-dir \
    fastapi==0.110.0 \
    uvicorn==0.27.1 \
    python-multipart==0.0.9 \
    openvino>=2024.0.0 \
    transformers>=4.35.0 \
    optimum-intel \
    librosa>=0.10.0 \
    soundfile>=0.12.0 \
    numpy==1.26.4 \
    scipy>=1.10.0 \
    huggingface-hub

# Download INT8 models from HuggingFace at build time
RUN mkdir -p /app/models && \
    echo "Downloading INT8 models from HuggingFace..." && \
    git clone https://huggingface.co/magicunicorn/whisper-base-int8 /app/models/whisper-base-int8 && \
    git clone https://huggingface.co/magicunicorn/whisper-large-v3-int8 /app/models/whisper-large-v3-int8 && \
    echo "Models downloaded successfully"

# Copy application files
COPY server_openvino_optimized.py /app/server.py
# Copy static and templates if they exist (handle in RUN command)
RUN mkdir -p /app/static /app/templates

# Create cache directory for OpenVINO
RUN mkdir -p /app/cache

# Set environment variables for Intel iGPU
ENV LIBVA_DRIVER_NAME=iHD
ENV LIBVA_DRIVERS_PATH=/usr/lib/x86_64-linux-gnu/dri
ENV GST_VAAPI_ALL_DRIVERS=1
ENV WHISPER_DEVICE=GPU
ENV WHISPER_MODEL=base
ENV PORT=9003

# Add model size mapping for INT8
ENV MODEL_MAPPING='{"base":"whisper-base-int8","large-v3":"whisper-large-v3-int8"}'

EXPOSE 9003

HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:9003/health || exit 1

CMD ["python3", "/app/server.py"]