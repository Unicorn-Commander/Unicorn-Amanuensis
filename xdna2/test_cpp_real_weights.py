#!/usr/bin/env python3
"""
Test C++ Encoder with Real Whisper Base Weights

Loads actual OpenAI Whisper Base encoder weights and tests the C++ implementation.
Compares performance and numerical accuracy against random weight baseline.
"""

import numpy as np
import ctypes
from ctypes import c_void_p, c_float, c_int, c_size_t, c_int8, c_int32, POINTER, CFUNCTYPE
import time
import sys
from pathlib import Path

# Add XRT bindings
sys.path.insert(0, "/opt/xilinx/xrt/python")

try:
    from aie.utils.xrt import AIE_Application
except ImportError as e:
    print(f"‚ùå Failed to load XRT bindings: {e}")
    sys.exit(1)

print("="*70)
print("  C++ ENCODER WITH REAL WHISPER WEIGHTS TEST")
print("="*70)

# Load C++ encoder library
lib_path = "/home/ccadmin/CC-1L/npu-services/unicorn-amanuensis/xdna2/cpp/build/libwhisper_encoder_cpp.so"
lib = ctypes.CDLL(lib_path)

# Define C API
lib.encoder_layer_create.argtypes = [c_size_t, c_size_t, c_size_t, c_size_t]
lib.encoder_layer_create.restype = c_void_p
lib.encoder_layer_destroy.argtypes = [c_void_p]
lib.encoder_layer_load_weights.argtypes = [
    c_void_p, POINTER(c_float), POINTER(c_float), POINTER(c_float), POINTER(c_float),
    POINTER(c_float), POINTER(c_float), POINTER(c_float), POINTER(c_float),
    POINTER(c_float), POINTER(c_float), POINTER(c_float), POINTER(c_float),
    POINTER(c_float), POINTER(c_float), POINTER(c_float), POINTER(c_float),
    c_size_t, c_size_t
]
lib.encoder_layer_load_weights.restype = c_int
lib.encoder_layer_forward.argtypes = [c_void_p, POINTER(c_float), POINTER(c_float), c_size_t, c_size_t]
lib.encoder_layer_forward.restype = c_int

NPUMatmulCallback = CFUNCTYPE(c_int, c_void_p, POINTER(c_int8), POINTER(c_int8), POINTER(c_int32), c_size_t, c_size_t, c_size_t)
lib.encoder_layer_set_npu_callback.argtypes = [c_void_p, NPUMatmulCallback, c_void_p]
lib.encoder_layer_set_npu_callback.restype = c_int

print("‚úÖ C++ library loaded")

# Load NPU kernel
print(f"\n{'='*70}")
print("  LOADING NPU KERNEL (32-TILE)")
print(f"{'='*70}")

kernel_dir = Path(__file__).parent / "kernels" / "common" / "build"
npu_app = AIE_Application(str(kernel_dir / "matmul_32tile_int8.xclbin"),
                          str(kernel_dir / "insts_32tile_int8.bin"),
                          kernel_name="MLIR_AIE")

# Allocate NPU buffers
MAX_M, MAX_K, MAX_N = 512, 2048, 2048
npu_app.register_buffer(3, np.int8, (MAX_M * MAX_K,))
npu_app.register_buffer(4, np.int8, (MAX_K * MAX_N,))
npu_app.register_buffer(5, np.int32, (MAX_M * MAX_N,))

print(f"‚úÖ NPU kernel loaded")

# NPU callback
def npu_matmul_callback(user_data, A_ptr, B_ptr, C_ptr, M, K, N):
    try:
        A = np.ctypeslib.as_array(A_ptr, shape=(M, K))
        B = np.ctypeslib.as_array(B_ptr, shape=(N, K))

        if M > MAX_M or K > MAX_K or N > MAX_N:
            C = A.astype(np.int32) @ B.astype(np.int32).T
            C_out = np.ctypeslib.as_array(C_ptr, shape=(M, N))
            C_out[:] = C
            return 0

        A_flat = np.zeros(MAX_M * MAX_K, dtype=np.int8)
        B_flat = np.zeros(MAX_K * MAX_N, dtype=np.int8)
        A_flat[:M*K] = A.flatten()
        B_flat[:K*N] = B.flatten()

        npu_app.buffers[3].write(A_flat)
        npu_app.buffers[4].write(B_flat)
        npu_app.run()

        C_flat = npu_app.buffers[5].read()
        C = C_flat[:M*N].reshape(M, N)
        C_out = np.ctypeslib.as_array(C_ptr, shape=(M, N))
        C_out[:] = C
        return 0
    except:
        return -1

npu_callback = NPUMatmulCallback(npu_matmul_callback)

# Load real Whisper weights
print(f"\n{'='*70}")
print("  LOADING REAL WHISPER BASE ENCODER WEIGHTS")
print(f"{'='*70}")

weights_dir = Path("./weights/whisper_base_fp32")
if not weights_dir.exists():
    print(f"‚ùå Weights directory not found: {weights_dir}")
    print("   Please run extract_whisper_weights.py first")
    sys.exit(1)

def load_weight(name):
    """Load a weight tensor from NumPy file."""
    path = weights_dir / f"{name}.npy"
    if not path.exists():
        raise FileNotFoundError(f"Weight not found: {path}")
    return np.load(path).astype(np.float32)

# Configuration
n_heads, n_state, ffn_dim, seq_len = 8, 512, 2048, 512

# Create 6 layers with real weights
print("\nCreating 6-layer encoder with REAL weights...")
layers = []

for layer_idx in range(6):
    print(f"\nLayer {layer_idx}:")
    handle = lib.encoder_layer_create(layer_idx, n_heads, n_state, ffn_dim)
    lib.encoder_layer_set_npu_callback(handle, npu_callback, None)

    # Load real weights for this layer
    try:
        # Attention weights
        q_w = load_weight(f"layers_{layer_idx}_self_attn_q_proj_weight").T  # Transpose for C++
        k_w = load_weight(f"layers_{layer_idx}_self_attn_k_proj_weight").T
        v_w = load_weight(f"layers_{layer_idx}_self_attn_v_proj_weight").T
        out_w = load_weight(f"layers_{layer_idx}_self_attn_out_proj_weight").T

        q_b = load_weight(f"layers_{layer_idx}_self_attn_q_proj_bias")
        k_b = np.zeros(n_state, dtype=np.float32)  # K projection has no bias in Whisper
        v_b = load_weight(f"layers_{layer_idx}_self_attn_v_proj_bias")
        out_b = load_weight(f"layers_{layer_idx}_self_attn_out_proj_bias")

        # FFN weights
        fc1_w = load_weight(f"layers_{layer_idx}_fc1_weight").T
        fc2_w = load_weight(f"layers_{layer_idx}_fc2_weight").T
        fc1_b = load_weight(f"layers_{layer_idx}_fc1_bias")
        fc2_b = load_weight(f"layers_{layer_idx}_fc2_bias")

        # Layer norm weights
        attn_ln_w = load_weight(f"layers_{layer_idx}_self_attn_layer_norm_weight")
        attn_ln_b = load_weight(f"layers_{layer_idx}_self_attn_layer_norm_bias")
        ffn_ln_w = load_weight(f"layers_{layer_idx}_final_layer_norm_weight")
        ffn_ln_b = load_weight(f"layers_{layer_idx}_final_layer_norm_bias")

        # Load into C++
        lib.encoder_layer_load_weights(
            handle,
            q_w.ctypes.data_as(POINTER(c_float)), k_w.ctypes.data_as(POINTER(c_float)),
            v_w.ctypes.data_as(POINTER(c_float)), out_w.ctypes.data_as(POINTER(c_float)),
            q_b.ctypes.data_as(POINTER(c_float)), k_b.ctypes.data_as(POINTER(c_float)),
            v_b.ctypes.data_as(POINTER(c_float)), out_b.ctypes.data_as(POINTER(c_float)),
            fc1_w.ctypes.data_as(POINTER(c_float)), fc2_w.ctypes.data_as(POINTER(c_float)),
            fc1_b.ctypes.data_as(POINTER(c_float)), fc2_b.ctypes.data_as(POINTER(c_float)),
            attn_ln_w.ctypes.data_as(POINTER(c_float)), attn_ln_b.ctypes.data_as(POINTER(c_float)),
            ffn_ln_w.ctypes.data_as(POINTER(c_float)), ffn_ln_b.ctypes.data_as(POINTER(c_float)),
            n_state, ffn_dim
        )

        layers.append(handle)
        print(f"  ‚úÖ Layer {layer_idx} loaded with REAL Whisper weights")

    except Exception as e:
        print(f"  ‚ùå Failed to load weights for layer {layer_idx}: {e}")
        sys.exit(1)

print(f"\n‚úÖ All 6 layers loaded with REAL WHISPER BASE WEIGHTS!")

# Prepare test input
print(f"\n{'='*70}")
print("  RUNNING PERFORMANCE TEST")
print(f"{'='*70}")

input_data = np.random.randn(seq_len, n_state).astype(np.float32)
buffer_a = np.zeros((seq_len, n_state), dtype=np.float32)

# Warmup
print("\nWarmup run...")
current = input_data.copy()
for handle in layers:
    lib.encoder_layer_forward(handle, current.ctypes.data_as(POINTER(c_float)),
                              buffer_a.ctypes.data_as(POINTER(c_float)), seq_len, n_state)
    current = buffer_a.copy()

print("‚úÖ Warmup complete")

# Benchmark
print("\nBenchmark runs (10 iterations)...")
times = []

for run in range(10):
    current = input_data.copy()
    start = time.perf_counter()

    for handle in layers:
        result = lib.encoder_layer_forward(handle, current.ctypes.data_as(POINTER(c_float)),
                                          buffer_a.ctypes.data_as(POINTER(c_float)), seq_len, n_state)
        if result != 0:
            print(f"‚ùå Forward pass failed")
            sys.exit(1)
        current = buffer_a.copy()

    elapsed = (time.perf_counter() - start) * 1000
    times.append(elapsed)
    print(f"  Run {run+1:2d}: {elapsed:7.2f} ms")

output_real = current.copy()

# Calculate statistics
avg_time = np.mean(times)
audio_duration = 10.24
realtime_factor = (audio_duration * 1000) / avg_time

print(f"\n{'='*70}")
print("  RESULTS WITH REAL WHISPER WEIGHTS")
print(f"{'='*70}")

print(f"\nPerformance:")
print(f"  Average:       {avg_time:.2f} ms")
print(f"  Min:           {np.min(times):.2f} ms")
print(f"  Max:           {np.max(times):.2f} ms")
print(f"  Std Dev:       {np.std(times):.2f} ms")

print(f"\nRealtime Factor:")
print(f"  Audio:         {audio_duration:.2f} seconds")
print(f"  Processing:    {avg_time:.0f} ms")
print(f"  Realtime:      {realtime_factor:.2f}√ó")

print(f"\nOutput Validation:")
print(f"  Valid:         {'‚úÖ Yes' if not (np.isnan(output_real).any() or np.isinf(output_real).any()) else '‚ùå No'}")
print(f"  Mean:          {output_real.mean():.4f}")
print(f"  Std:           {output_real.std():.4f}")
print(f"  Min:           {output_real.min():.4f}")
print(f"  Max:           {output_real.max():.4f}")

if realtime_factor >= 17:
    print(f"\nüéâ TARGET ACHIEVED: {realtime_factor:.2f}√ó >= 17√ó!")
else:
    print(f"\n‚è≥ Below target: {realtime_factor:.2f}√ó")

# Cleanup
for handle in layers:
    lib.encoder_layer_destroy(handle)

print(f"\n{'='*70}")
print(f"  ‚úÖ REAL WEIGHT TEST COMPLETE")
print(f"{'='*70}")

print(f"\nüéØ Summary:")
print(f"  Weights:       REAL OpenAI Whisper Base")
print(f"  Layers:        6 (complete encoder)")
print(f"  Performance:   {realtime_factor:.2f}√ó realtime")
print(f"  NPU:           32-tile INT8 kernel")
print(f"  Status:        {'‚úÖ READY FOR PRODUCTION' if realtime_factor >= 17 else '‚è≥ Needs optimization'}")
